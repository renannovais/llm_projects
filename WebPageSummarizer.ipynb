{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce13728-0040-43cc-82cd-e10c838ef71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Detected language: PT\n",
      "üîó Preview of extracted text:\n",
      "\n",
      "ITASAT2 ir√° atuar para aplica√ß√µes cient√≠ficas e de defesa\n",
      "Publicado em 14/04/2025 - 14h15\n",
      "O Instituto Tecnol√≥gico de Aeron√°utica (ITA) realizou, entre os dias 17 e 19 de mar√ßo, a Revis√£o Preliminar de Projeto (PDR) do ITASAT 2, novo microssat√©lite em desenvolvimento por pesquisadores do Centro Espacial ITA (CEI). A atividade representa uma etapa importante dos estudos e contou com a presen√ßa de institui√ß√µes parceiras, tanto do Brasil quanto do exterior.\n",
      "Participaram do encontro representantes do\n",
      "...\n",
      "\n",
      "Amount of words: 526\n",
      "\n",
      "\n",
      "# üìù Summary\n",
      "\n",
      "Exciting developments are happening at the Instituto Tecnol√≥gico de Aeron√°utica (ITA) with the ITASAT 2 project, a new microsatellite being designed for scientific and defense applications! üöÄ Between March 17-19, 2025, the Preliminary Design Review (PDR) was conducted, marking a significant milestone in the project. The review involved various partners, including prominent institutions like NASA and the U.S. Southern Command‚Äîdemonstrating international collaboration in space research!\n",
      "\n",
      "The ITASAT 2 will consist of a constellation of three CubeSats, aimed at monitoring the Earth‚Äôs ionosphere and analyzing plasma bubble formation and impact. In defense applications, it promises to enhance radiofrequency geolocation on land and sea while also identifying non-collaborative vessels‚Äîtalk about advanced technology! üåê\n",
      "\n",
      "Feedback from participants, including Professor Lu√≠s Eduardo Vergueiro Loures da Costa, highlighted the comprehensive understanding and capabilities of the ITASAT 2 team. Master‚Äôs student D√©bora Santos expressed that the review was incredibly productive, showcasing the team's effort and preparation.\n",
      "\n",
      "Fascinatingly, CubeSats like the ITASAT 2 consist of cubic units, with ITASAT 2 being a 16U model made up of 16 units. ITA has a history of satellite development, including ITASAT 1 and the SPORT mission, indicating a solid track record in space exploration! Plus, there are more exciting projects on the horizon, like the SelenITA CubeSat, which will be part of NASA's Artemis mission to study the Moon! üåï \n",
      "\n",
      "The future of space research at ITA looks incredibly promising, and I'm thrilled to see where this journey will lead! üåü\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from langdetect import detect, LangDetectException\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load .env variables\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"‚ö†Ô∏è OPENAI_API_KEY not found in .env file.\")\n",
    "\n",
    "# Generating object to work with GPT tasks \n",
    "openai = OpenAI()\n",
    "\n",
    "# Class to work with text extraction, processing and summarizing from a given url\n",
    "class WebPageSummarizer():\n",
    "    \"\"\"\n",
    "        Class to work with text extraction, processing and summarizing from a given url using the BeautifulSoup library.\n",
    "    \"\"\"\n",
    "    def __init__(self, url: str, summary_detail: str = \"high\", show_summary: bool = True, language_of_reference = \"English\") -> None:\n",
    "\n",
    "        # Initial summarizer settings\n",
    "        self.url = url\n",
    "        self.show_summary = show_summary\n",
    "        self.summary_detail = summary_detail\n",
    "        self.language_of_reference = language_of_reference\n",
    "        self.language_code_map = {\n",
    "            \"english\": \"en\",\n",
    "            \"portuguese\": \"pt\",\n",
    "            \"spanish\": \"es\",\n",
    "            \"french\": \"fr\",\n",
    "            \"german\": \"de\",\n",
    "            \"italian\": \"it\",\n",
    "            \"japanese\": \"ja\",\n",
    "            \"chinese\": \"zh\",\n",
    "            \"korean\": \"ko\",\n",
    "        }\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                          \"(KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        if self.summary_detail not in [\"high\", \"low\"]:\n",
    "            raise Exception(\"\"\"Please select summary detail as either \"high\" or \"low\".\"\"\")\n",
    "\n",
    "    def __extract_text(self):\n",
    "        response = requests.get(self.url, headers=self.headers)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to fetch page. Status code: {response.status_code}\")\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Try to extract meaningful content\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        \n",
    "        # Join all paragraph text\n",
    "        self.text = \"\\n\".join([p.get_text() for p in paragraphs if p.get_text().strip() != \"\"])\n",
    "\n",
    "        # Guarantee limit of text to summary\n",
    "        max_words = 7000\n",
    "        if len(self.text.split()) > max_words:\n",
    "            self.text = \" \".join(self.text.split()[:max_words])\n",
    "    \n",
    "    def __detect_language(self):\n",
    "        # Detect language\n",
    "        try:\n",
    "            self.language_url = detect(self.text)\n",
    "        except LangDetectException:\n",
    "            self.language_url = \"unknown\"\n",
    "\n",
    "        # Normalize and resolve target language code\n",
    "        target_language_name = self.language_of_reference.lower().strip()\n",
    "        self.target_language_code = self.language_code_map.get(target_language_name)\n",
    "        \n",
    "        if not self.target_language_code:\n",
    "            raise ValueError(f\"‚ùå Unsupported language: {self.language_of_reference}. Please use one of: {list(LANGUAGE_CODE_MAP.keys())}\")\n",
    "\n",
    "        print(f\"üåç Detected language: {self.language_url.upper()}\")\n",
    "        \n",
    "        if self.show_summary:\n",
    "            print(\"üîó Preview of extracted text:\\n\")\n",
    "            print(self.text[:500] + \"\\n...\\n\")\n",
    "            print(f\"Amount of words: {len(self.text.split())}\\n\\n\")\n",
    "\n",
    "    def summarize(self)-> str:\n",
    "        \"\"\"Method to process user prompts in the context of the user.\"\"\"\n",
    "        self.__extract_text()\n",
    "        self.__detect_language()\n",
    "        \n",
    "        # Prompt for system definition\n",
    "        self.system_prompt = f\"\"\" \n",
    "        You are an assistant that analyzes the contents of a website and provides a summary. \n",
    "        Please notice that providing a {self.summary_detail} summary detail is IMPORTANT.\n",
    "        If you find text that might be navigation related or ad related please ignore. Respond in markdown. Also, can you please start your summary \n",
    "        with the tile \"üìù Summary\"?\n",
    "        \n",
    "        Please show some excited behavior during your summary, making comments with extra knowledge if possible during or at the end of the sentence. \n",
    "        \"\"\"\n",
    "\n",
    "        self.content = f\"\"\"The text to summarize is as follows: {self.text}\"\"\"\n",
    "\n",
    "        if self.language_url != self.target_language_code:\n",
    "            self.system_prompt = f\"\"\"The website content is in {self.language_url.upper()}. Please first translate it to {self.language_of_reference}. \n",
    "            {self.system_prompt.strip()}\n",
    "            \"\"\"\n",
    "\n",
    "        response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"system\", \"content\":self.system_prompt}, \n",
    "                                                                                 {\"role\": \"user\",  \"content\":self.content}])\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "web_page_summarizer = WebPageSummarizer(\"http://www.ita.br/noticias/revisodeprojetodonovomicrossatlitedoitaaprovada\", summary_detail = \"low\")\n",
    "print(web_page_summarizer.summarize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb250f0-7e87-471a-bbe9-67c4908498dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
