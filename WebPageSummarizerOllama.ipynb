{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce13728-0040-43cc-82cd-e10c838ef71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ Detected language: PT\n",
      "ğŸ”— Preview of extracted text:\n",
      "\n",
      "ITASAT2 irÃ¡ atuar para aplicaÃ§Ãµes cientÃ­ficas e de defesa\n",
      "Publicado em 14/04/2025 - 14h15\n",
      "O Instituto TecnolÃ³gico de AeronÃ¡utica (ITA) realizou, entre os dias 17 e 19 de marÃ§o, a RevisÃ£o Preliminar de Projeto (PDR) do ITASAT 2, novo microssatÃ©lite em desenvolvimento por pesquisadores do Centro Espacial ITA (CEI). A atividade representa uma etapa importante dos estudos e contou com a presenÃ§a de instituiÃ§Ãµes parceiras, tanto do Brasil quanto do exterior.\n",
      "Participaram do encontro representantes do\n",
      "...\n",
      "\n",
      "Amount of words: 526\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "ğŸ“ Summary\n",
       "Oh boy, get ready for some exciting space-related news! ğŸš€ The Instituto TecnolÃ³gico de AeronÃ¡utica (ITA) has just concluded the Preliminary Design Review (PDR) of their new microsatellite project, ITASAT 2! ğŸ‰ This innovative satellite is expected to launch in the coming years and will be a constellation of three cubesats responsible for monitoring the Earth's ionosphere. ğŸ”­ Not only that, but it'll also enable geolocation of radiofrequency sources on land and sea, as well as optical identification of non-collaborative vessels! ğŸš¢\n",
       "\n",
       "The PDR was attended by representatives from various institutions, including ITA, CENSIPAM, DGDNTM, AEB, INPE, FINEP, NASA, Comando Sul dos Estados Unidos, NRL, and Utah State University. ğŸŒ This event marks an important milestone in the project's development, showcasing the team's understanding of the objectives and their ability to propose solutions and identify risks! ğŸ’¡\n",
       "\n",
       "As you might know, cubesats are small satellites structured in cubic units, each 10 cm on a side. In this case, ITASAT 2 is composed of 16 such units, making it a total of 16U. ğŸ“Š The ITA has a rich history of developing and launching satellites for research and student training, including the ITASAT 1 and SPORT projects! ğŸš€\n",
       "\n",
       "That's not all, folks! ğŸ˜„ The CEI is also working on the SelenITA project, a CubeSat that will be part of NASA's Artemis mission to study the Moon! ğŸŒ• Stay tuned for more updates on this exciting development in space technology! ğŸš€"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load .env variables\n",
    "ollama_api = \"http://localhost:11434/api/chat\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "model = \"llama3\"\n",
    "\n",
    "# Class to work with text extraction, processing and summarizing from a given url\n",
    "class WebPageSummarizer():\n",
    "    \"\"\"\n",
    "        Class to work with text extraction, processing and summarizing from a given url using the BeautifulSoup library.\n",
    "    \"\"\"\n",
    "    def __init__(self, url: str, summary_detail: str = \"high\", show_summary: bool = True, language_of_reference = \"English\", model: str = \"gpt-4o-mini\") -> None:\n",
    "\n",
    "        # Initial summarizer settings\n",
    "        self.url = url\n",
    "        self.model = model\n",
    "        self.show_summary = show_summary\n",
    "        self.summary_detail = summary_detail\n",
    "        self.language_of_reference = language_of_reference\n",
    "        self.language_code_map = {\n",
    "            \"english\": \"en\",\n",
    "            \"portuguese\": \"pt\",\n",
    "            \"spanish\": \"es\",\n",
    "            \"french\": \"fr\",\n",
    "            \"german\": \"de\",\n",
    "            \"italian\": \"it\",\n",
    "            \"japanese\": \"ja\",\n",
    "            \"chinese\": \"zh\",\n",
    "            \"korean\": \"ko\",\n",
    "        }\n",
    "        \n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                          \"(KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        if self.summary_detail not in [\"high\", \"low\"]:\n",
    "            raise Exception(\"\"\"Please select summary detail as either \"high\" or \"low\".\"\"\")\n",
    "\n",
    "    def __extract_text(self):\n",
    "        response = requests.get(self.url, headers=self.headers)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to fetch page. Status code: {response.status_code}\")\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Try to extract meaningful content\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        \n",
    "        # Join all paragraph text\n",
    "        self.text = \"\\n\".join([p.get_text() for p in paragraphs if p.get_text().strip() != \"\"])\n",
    "\n",
    "        # Guarantee limit of text to summary\n",
    "        max_words = 7000\n",
    "        if len(self.text.split()) > max_words:\n",
    "            self.text = \" \".join(self.text.split()[:max_words])\n",
    "    \n",
    "    def __detect_language(self):\n",
    "        # Detect language\n",
    "        try:\n",
    "            self.language_url = detect(self.text)\n",
    "        except LangDetectException:\n",
    "            self.language_url = \"unknown\"\n",
    "\n",
    "        # Normalize and resolve target language code\n",
    "        target_language_name = self.language_of_reference.lower().strip()\n",
    "        self.target_language_code = self.language_code_map.get(target_language_name)\n",
    "        \n",
    "        if not self.target_language_code:\n",
    "            raise ValueError(f\"âŒ Unsupported language: {self.language_of_reference}. Please use one of: {list(LANGUAGE_CODE_MAP.keys())}\")\n",
    "\n",
    "        print(f\"ğŸŒ Detected language: {self.language_url.upper()}\")\n",
    "        \n",
    "        if self.show_summary:\n",
    "            print(\"ğŸ”— Preview of extracted text:\\n\")\n",
    "            print(self.text[:500] + \"\\n...\\n\")\n",
    "            print(f\"Amount of words: {len(self.text.split())}\\n\")\n",
    "\n",
    "    def summarize(self)-> str:\n",
    "        \"\"\"\n",
    "        Method to process user prompts in the context of the user.\n",
    "        \"\"\"\n",
    "        self.__extract_text()\n",
    "        self.__detect_language()\n",
    "        \n",
    "        # Prompt for system definition\n",
    "        self.system_prompt = f\"\"\" \n",
    "        You are an assistant that analyzes the contents of a website and provides a summary. \n",
    "        Please notice that providing a {self.summary_detail} summary detail is IMPORTANT.\n",
    "        If you find text that might be navigation related or ad related please ignore. Respond in markdown. \n",
    "        Also, can you please start your summary with the tile \"ğŸ“ Summary\"?\n",
    "        \n",
    "        Please show some excited behavior during your summary, making comments with extra knowledge if possible during or at the end of the sentence. \n",
    "        \"\"\"\n",
    "\n",
    "        self.content = f\"\"\"The text to summarize is as follows: {self.text}\"\"\"\n",
    "\n",
    "        if self.language_url != self.target_language_code:\n",
    "            self.system_prompt = f\"\"\"The website content is in {self.language_url.upper()}. Please first translate it to {self.language_of_reference}. \n",
    "            {self.system_prompt.strip()}\n",
    "            \"\"\"\n",
    "\n",
    "        messages=[{\"role\":\"system\", \"content\":self.system_prompt}, \n",
    "                  {\"role\": \"user\",  \"content\":self.content}]\n",
    "\n",
    "        response = requests.post(ollama_api, json = {\"model\": model, \"messages\": messages, \"stream\": False}, headers = headers)\n",
    "\n",
    "        # Cost calculation and usage report\n",
    "        return response.json()[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "web_page_summarizer = WebPageSummarizer(\"http://www.ita.br/noticias/revisodeprojetodonovomicrossatlitedoitaaprovada\", summary_detail = \"low\")\n",
    "display(Markdown(web_page_summarizer.summarize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a186a-bb25-4cf4-a6d2-6034cd493bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
