{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce13728-0040-43cc-82cd-e10c838ef71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 Detected language: PT\n",
      "🔗 Preview of extracted text:\n",
      "\n",
      "ITASAT2 irá atuar para aplicações científicas e de defesa\n",
      "Publicado em 14/04/2025 - 14h15\n",
      "O Instituto Tecnológico de Aeronáutica (ITA) realizou, entre os dias 17 e 19 de março, a Revisão Preliminar de Projeto (PDR) do ITASAT 2, novo microssatélite em desenvolvimento por pesquisadores do Centro Espacial ITA (CEI). A atividade representa uma etapa importante dos estudos e contou com a presença de instituições parceiras, tanto do Brasil quanto do exterior.\n",
      "Participaram do encontro representantes do\n",
      "...\n",
      "\n",
      "Amount of words: 526\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "📝 Summary\n",
       "Oh boy, get ready for some exciting space-related news! 🚀 The Instituto Tecnológico de Aeronáutica (ITA) has just concluded the Preliminary Design Review (PDR) of their new microsatellite project, ITASAT 2! 🎉 This innovative satellite is expected to launch in the coming years and will be a constellation of three cubesats responsible for monitoring the Earth's ionosphere. 🔭 Not only that, but it'll also enable geolocation of radiofrequency sources on land and sea, as well as optical identification of non-collaborative vessels! 🚢\n",
       "\n",
       "The PDR was attended by representatives from various institutions, including ITA, CENSIPAM, DGDNTM, AEB, INPE, FINEP, NASA, Comando Sul dos Estados Unidos, NRL, and Utah State University. 🌎 This event marks an important milestone in the project's development, showcasing the team's understanding of the objectives and their ability to propose solutions and identify risks! 💡\n",
       "\n",
       "As you might know, cubesats are small satellites structured in cubic units, each 10 cm on a side. In this case, ITASAT 2 is composed of 16 such units, making it a total of 16U. 📊 The ITA has a rich history of developing and launching satellites for research and student training, including the ITASAT 1 and SPORT projects! 🚀\n",
       "\n",
       "That's not all, folks! 😄 The CEI is also working on the SelenITA project, a CubeSat that will be part of NASA's Artemis mission to study the Moon! 🌕 Stay tuned for more updates on this exciting development in space technology! 🚀"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load .env variables\n",
    "ollama_api = \"http://localhost:11434/api/chat\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "model = \"llama3\"\n",
    "\n",
    "# Class to work with text extraction, processing and summarizing from a given url\n",
    "class WebPageSummarizer():\n",
    "    \"\"\"\n",
    "        Class to work with text extraction, processing and summarizing from a given url using the BeautifulSoup library.\n",
    "    \"\"\"\n",
    "    def __init__(self, url: str, summary_detail: str = \"high\", show_summary: bool = True, language_of_reference = \"English\", model: str = \"gpt-4o-mini\") -> None:\n",
    "\n",
    "        # Initial summarizer settings\n",
    "        self.url = url\n",
    "        self.model = model\n",
    "        self.show_summary = show_summary\n",
    "        self.summary_detail = summary_detail\n",
    "        self.language_of_reference = language_of_reference\n",
    "        self.language_code_map = {\n",
    "            \"english\": \"en\",\n",
    "            \"portuguese\": \"pt\",\n",
    "            \"spanish\": \"es\",\n",
    "            \"french\": \"fr\",\n",
    "            \"german\": \"de\",\n",
    "            \"italian\": \"it\",\n",
    "            \"japanese\": \"ja\",\n",
    "            \"chinese\": \"zh\",\n",
    "            \"korean\": \"ko\",\n",
    "        }\n",
    "        \n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                          \"(KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        if self.summary_detail not in [\"high\", \"low\"]:\n",
    "            raise Exception(\"\"\"Please select summary detail as either \"high\" or \"low\".\"\"\")\n",
    "\n",
    "    def __extract_text(self):\n",
    "        response = requests.get(self.url, headers=self.headers)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to fetch page. Status code: {response.status_code}\")\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Try to extract meaningful content\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        \n",
    "        # Join all paragraph text\n",
    "        self.text = \"\\n\".join([p.get_text() for p in paragraphs if p.get_text().strip() != \"\"])\n",
    "\n",
    "        # Guarantee limit of text to summary\n",
    "        max_words = 7000\n",
    "        if len(self.text.split()) > max_words:\n",
    "            self.text = \" \".join(self.text.split()[:max_words])\n",
    "    \n",
    "    def __detect_language(self):\n",
    "        # Detect language\n",
    "        try:\n",
    "            self.language_url = detect(self.text)\n",
    "        except LangDetectException:\n",
    "            self.language_url = \"unknown\"\n",
    "\n",
    "        # Normalize and resolve target language code\n",
    "        target_language_name = self.language_of_reference.lower().strip()\n",
    "        self.target_language_code = self.language_code_map.get(target_language_name)\n",
    "        \n",
    "        if not self.target_language_code:\n",
    "            raise ValueError(f\"❌ Unsupported language: {self.language_of_reference}. Please use one of: {list(LANGUAGE_CODE_MAP.keys())}\")\n",
    "\n",
    "        print(f\"🌍 Detected language: {self.language_url.upper()}\")\n",
    "        \n",
    "        if self.show_summary:\n",
    "            print(\"🔗 Preview of extracted text:\\n\")\n",
    "            print(self.text[:500] + \"\\n...\\n\")\n",
    "            print(f\"Amount of words: {len(self.text.split())}\\n\")\n",
    "\n",
    "    def summarize(self)-> str:\n",
    "        \"\"\"\n",
    "        Method to process user prompts in the context of the user.\n",
    "        \"\"\"\n",
    "        self.__extract_text()\n",
    "        self.__detect_language()\n",
    "        \n",
    "        # Prompt for system definition\n",
    "        self.system_prompt = f\"\"\" \n",
    "        You are an assistant that analyzes the contents of a website and provides a summary. \n",
    "        Please notice that providing a {self.summary_detail} summary detail is IMPORTANT.\n",
    "        If you find text that might be navigation related or ad related please ignore. Respond in markdown. \n",
    "        Also, can you please start your summary with the tile \"📝 Summary\"?\n",
    "        \n",
    "        Please show some excited behavior during your summary, making comments with extra knowledge if possible during or at the end of the sentence. \n",
    "        \"\"\"\n",
    "\n",
    "        self.content = f\"\"\"The text to summarize is as follows: {self.text}\"\"\"\n",
    "\n",
    "        if self.language_url != self.target_language_code:\n",
    "            self.system_prompt = f\"\"\"The website content is in {self.language_url.upper()}. Please first translate it to {self.language_of_reference}. \n",
    "            {self.system_prompt.strip()}\n",
    "            \"\"\"\n",
    "\n",
    "        messages=[{\"role\":\"system\", \"content\":self.system_prompt}, \n",
    "                  {\"role\": \"user\",  \"content\":self.content}]\n",
    "\n",
    "        response = requests.post(ollama_api, json = {\"model\": model, \"messages\": messages, \"stream\": False}, headers = headers)\n",
    "\n",
    "        # Cost calculation and usage report\n",
    "        return response.json()[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "web_page_summarizer = WebPageSummarizer(\"http://www.ita.br/noticias/revisodeprojetodonovomicrossatlitedoitaaprovada\", summary_detail = \"low\")\n",
    "display(Markdown(web_page_summarizer.summarize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a186a-bb25-4cf4-a6d2-6034cd493bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
