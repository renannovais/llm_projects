{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce13728-0040-43cc-82cd-e10c838ef71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Detected language: PT\n",
      "üîó Preview of extracted text:\n",
      "\n",
      "ITASAT2 ir√° atuar para aplica√ß√µes cient√≠ficas e de defesa\n",
      "Publicado em 14/04/2025 - 14h15\n",
      "O Instituto Tecnol√≥gico de Aeron√°utica (ITA) realizou, entre os dias 17 e 19 de mar√ßo, a Revis√£o Preliminar de Projeto (PDR) do ITASAT 2, novo microssat√©lite em desenvolvimento por pesquisadores do Centro Espacial ITA (CEI). A atividade representa uma etapa importante dos estudos e contou com a presen√ßa de institui√ß√µes parceiras, tanto do Brasil quanto do exterior.\n",
      "Participaram do encontro representantes do\n",
      "...\n",
      "\n",
      "Amount of words: 526\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "üìù Summary\n",
       "Oh boy, are you ready for some exciting news?! The Instituto Tecnol√≥gico de Aeron√°utica (ITA) just had a crucial meeting to review the project of their new microsatellite, ITASAT2! This tiny but mighty satellite will be used for scientific applications and defense purposes. Let me give you the lowdown:\n",
       "\n",
       "ITASAT2 is a constellation of three cubesats that will monitor the Earth's ionosphere, tracking plasma bubbles and identifying non-collaborative vessels. It's scheduled to launch in the next few years! The meeting was attended by representatives from various organizations, including the Brazilian government, NASA, and more.\n",
       "\n",
       "The ITASAT2 project is a huge deal, requiring expertise from multiple engineering fields, such as orbital mechanics, control systems, propulsion, structures, and thermal management. After a thorough review, the project received unanimous approval to move forward!\n",
       "\n",
       "One of the team members, D√©bora Santos, described the meeting as \"extremely productive\" for both the reviewers and the team. She praised the well-structured presentations and the team's commitment and competence.\n",
       "\n",
       "Now, let me tell you about cubesats! They're tiny satellites that come in units called 1U, which measures 10 cm on each side. ITASAT2 is a 16U cube sat, composed of 16 of these units. The ITA has a rich history of developing satellites, including the ITASAT1, launched in 2018, and the SPORT, launched in 2022.\n",
       "\n",
       "The CEI is also working on another exciting project called SelenITA, which will be part of NASA's Artemis mission to study the Moon!\n",
       "\n",
       "That's it for now!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import requests\n",
    "import ollama\n",
    "from bs4 import BeautifulSoup\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load .env variables\n",
    "ollama_api = \"http://localhost:11434/api/chat\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "model = \"llama3\"\n",
    "\n",
    "# Class to work with text extraction, processing and summarizing from a given url\n",
    "class WebPageSummarizer():\n",
    "    \"\"\"\n",
    "        Class to work with text extraction, processing and summarizing from a given url using the BeautifulSoup library.\n",
    "    \"\"\"\n",
    "    def __init__(self, url: str, summary_detail: str = \"high\", show_summary: bool = True, language_of_reference = \"English\", model: str = \"gpt-4o-mini\") -> None:\n",
    "\n",
    "        # Initial summarizer settings\n",
    "        self.url = url\n",
    "        self.model = model\n",
    "        self.show_summary = show_summary\n",
    "        self.summary_detail = summary_detail\n",
    "        self.language_of_reference = language_of_reference\n",
    "        self.language_code_map = {\n",
    "            \"english\": \"en\",\n",
    "            \"portuguese\": \"pt\",\n",
    "            \"spanish\": \"es\",\n",
    "            \"french\": \"fr\",\n",
    "            \"german\": \"de\",\n",
    "            \"italian\": \"it\",\n",
    "            \"japanese\": \"ja\",\n",
    "            \"chinese\": \"zh\",\n",
    "            \"korean\": \"ko\",\n",
    "        }\n",
    "        \n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                          \"(KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\n",
    "        }\n",
    "\n",
    "        if self.summary_detail not in [\"high\", \"low\"]:\n",
    "            raise Exception(\"\"\"Please select summary detail as either \"high\" or \"low\".\"\"\")\n",
    "\n",
    "    def __extract_text(self):\n",
    "        response = requests.get(self.url, headers=self.headers)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to fetch page. Status code: {response.status_code}\")\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Try to extract meaningful content\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        \n",
    "        # Join all paragraph text\n",
    "        self.text = \"\\n\".join([p.get_text() for p in paragraphs if p.get_text().strip() != \"\"])\n",
    "\n",
    "        # Guarantee limit of text to summary\n",
    "        max_words = 7000\n",
    "        if len(self.text.split()) > max_words:\n",
    "            self.text = \" \".join(self.text.split()[:max_words])\n",
    "    \n",
    "    def __detect_language(self):\n",
    "        # Detect language\n",
    "        try:\n",
    "            self.language_url = detect(self.text)\n",
    "        except LangDetectException:\n",
    "            self.language_url = \"unknown\"\n",
    "\n",
    "        # Normalize and resolve target language code\n",
    "        target_language_name = self.language_of_reference.lower().strip()\n",
    "        self.target_language_code = self.language_code_map.get(target_language_name)\n",
    "        \n",
    "        if not self.target_language_code:\n",
    "            raise ValueError(f\"‚ùå Unsupported language: {self.language_of_reference}. Please use one of: {list(LANGUAGE_CODE_MAP.keys())}\")\n",
    "\n",
    "        print(f\"üåç Detected language: {self.language_url.upper()}\")\n",
    "        \n",
    "        if self.show_summary:\n",
    "            print(\"üîó Preview of extracted text:\\n\")\n",
    "            print(self.text[:500] + \"\\n...\\n\")\n",
    "            print(f\"Amount of words: {len(self.text.split())}\\n\")\n",
    "\n",
    "    def summarize(self)-> str:\n",
    "        \"\"\"\n",
    "        Method to process user prompts in the context of the user.\n",
    "        \"\"\"\n",
    "        self.__extract_text()\n",
    "        self.__detect_language()\n",
    "        \n",
    "        # Prompt for system definition\n",
    "        self.system_prompt = f\"\"\" \n",
    "        You are an assistant that analyzes the contents of a website and provides a summary. \n",
    "        Please notice that providing a {self.summary_detail} summary detail is IMPORTANT.\n",
    "        If you find text that might be navigation related or ad related please ignore. Respond in markdown. \n",
    "        Also, can you please start your summary with the tile \"üìù Summary\"?\n",
    "        \n",
    "        Please show some excited behavior during your summary, making comments with extra knowledge if possible during or at the end of the sentence. \n",
    "        \"\"\"\n",
    "\n",
    "        self.content = f\"\"\"The text to summarize is as follows: {self.text}\"\"\"\n",
    "\n",
    "        if self.language_url != self.target_language_code:\n",
    "            self.system_prompt = f\"\"\"The website content is in {self.language_url.upper()}. Please first translate it to {self.language_of_reference}. \n",
    "            {self.system_prompt.strip()}\n",
    "            \"\"\"\n",
    "\n",
    "        messages=[{\"role\":\"system\", \"content\":self.system_prompt}, \n",
    "                  {\"role\": \"user\",  \"content\":self.content}]\n",
    "\n",
    "        response = ollama.chat(model = model, messages = messages)\n",
    "\n",
    "        # Cost calculation and usage report\n",
    "        return response[\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "web_page_summarizer = WebPageSummarizer(\"http://www.ita.br/noticias/revisodeprojetodonovomicrossatlitedoitaaprovada\", summary_detail = \"low\")\n",
    "display(Markdown(web_page_summarizer.summarize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a186a-bb25-4cf4-a6d2-6034cd493bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
